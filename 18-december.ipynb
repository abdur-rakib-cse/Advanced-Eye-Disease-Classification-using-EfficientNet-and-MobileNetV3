{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6856143,"sourceType":"datasetVersion","datasetId":3940905}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is a general purpose image classifier that can be applied to datasets that have the data organized as shown below. To use this code select Run all. The code will prompt the user to provide the required input data. It will take only a minute or so to enter the data and your model will be up and training. I have used this code on numerous data sets with excellent results. The model will initially run for 10 epochs. After 10 epochs you are prompted to enter H to halt training or you can enter an integer that specifies how many more epochs to run. After those epochs complete you will be again prompted to continue or halt training. The code shows the % decreasee  of the validation loss at the end of each epoch. This is a good guide to use to decide to continue or halt training. As you near the bottom of the loss function the % decrease in loss becomes smaller. I typically halt training when the % decrease falls below 5%. However sometimes it is best to continue training until the loss increases. The code then automatically lowers the learning rate. This often enables the model to again start decreasing the loss. Your saved model is always returned with the weights set to those for the epoch with the lowest loss.   \n\ndata directory  \n* train directory    \n  * class 0 \n     * image 0 \n     * image 1\n     * ......\n     * image m\n  * class 1\n     * image 0 \n     * image 1\n     * ......\n     * image n \n  * ......\n  * class m\n     * image 0 \n     * image 1\n     * ......\n     * image r \n* valid directory ( optional if there is no validation directory validation data is created by partition of train data)  \n   * class 0 \n     * image 0 \n     * image 1\n     * ......\n     * image x\n   * class 1\n     * image 0 \n     * image 1\n     * ......\n     * image y \n   * ......\n   * class m\n     * image 0 \n     * image 1\n     * ......\n     * image z\n* test directory ( optional if there is no test directory test data is created by partition of train data)  \n   * class 0 \n     * image 0 \n     * image 1\n     * ......\n     * image a\n   * class 1\n     * image 0 \n     * image 1\n     * ......\n     * image b \n   * ......\n   * class m\n     * image 0 \n     * image 1\n     * ......\n     * image c","metadata":{}},{"cell_type":"markdown","source":"### Recently Kaggle updated its docker file to load tensorflow 2.11.0. where before it loaded version 2.9.2 . However version 2.10.0 and above have a bug with respect to saving EfficientNet models. In my code if you select a medium or large model, the result is an EfficientNetB0 or B3 model is generated. So when you try to save the model you will receive a message saying the model can not be saved. If you want to save your model, uncomment the code line below which will install tensorflow version 2.9.2.","metadata":{}},{"cell_type":"markdown","source":"## [1. Import Needed Modules](#import) ##\n## [2 Define a function to print text in color](#pc) ##\n## [3. Define a function to plot the number of images in dataset classes](#pcounts) ##\n## [4 Define a function to return information on the dataset](#check) ##\n## [5. Read in images and create a dataframe of image paths and class labels](#makedf) ## \n## [6. Define a function that trims a dataset for the max number of class images](#trim) ## \n## [7. Balance the trainning set using augmentation](#Balance) ##\n## [8. Create train, test and validation generators](#gens) ## \n## [9. Create a function to show Training Image Samples](#show) ## \n## [10 Create a function to calculate the F1 score metric](#f1metric) ##\n## [11. Create the Model](#model) ## \n## [12. Create a custom Keras callback to continue or halt training](#callback) ## \n## [13. Define a function to plot the training data](#plot) ##\n## [14. Define a function save the training data to a csv file](#csv) ##\n## [15. Define a function to make predictions on the test set](#predict) ##\n## [16. Make predictions on test set, create Confusion Matrix and Classification Report](#result) \n## [17. Define a function to save the trained model ](#save) ##\n## [18 Define the run function which runs the classifier](#run) ##\n## [19 Define the code to enable to initiate the run function](#cycle) ##\n## [20. Evaluate Model Performance](#Conclusions) ## ","metadata":{}},{"cell_type":"code","source":" #pip install tensorflow==2.9.2","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:41.817129Z","iopub.execute_input":"2023-12-17T23:32:41.817514Z","iopub.status.idle":"2023-12-17T23:32:41.821912Z","shell.execute_reply.started":"2023-12-17T23:32:41.817483Z","shell.execute_reply":"2023-12-17T23:32:41.821054Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"import\"></a>\n## <center>Import required modules</center>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nimport time\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport shutil\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nimport albumentations as A\nimport time\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score\nfrom IPython.display import YouTubeVideo\nimport sys\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\npd.set_option('display.max_columns', None)  # or 1000\npd.set_option('display.max_rows', None)  # or 1000\npd.set_option('display.max_colwidth', None)  # or 199","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:41.823898Z","iopub.execute_input":"2023-12-17T23:32:41.824188Z","iopub.status.idle":"2023-12-17T23:32:41.836560Z","shell.execute_reply.started":"2023-12-17T23:32:41.824164Z","shell.execute_reply":"2023-12-17T23:32:41.835686Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"print('tensor version is ', tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:41.837566Z","iopub.execute_input":"2023-12-17T23:32:41.837792Z","iopub.status.idle":"2023-12-17T23:32:41.852936Z","shell.execute_reply.started":"2023-12-17T23:32:41.837772Z","shell.execute_reply":"2023-12-17T23:32:41.852205Z"},"trusted":true},"execution_count":167,"outputs":[{"name":"stdout","text":"tensor version is  2.9.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id=\"pc\"></a>\n## <center>Define a function to print text in specified rgb foreground and background colors</center>\n### Add some PZAZZ to your printed output with this function  \nform of the call is:  print_in_color(txt_msg, fore_tupple, back_tupple where:\n* txt_msg is the string to be printed out  \n* fore_tuple is tuple of the form (r,g,b) specifying the foreground color of the text\n* back_tuple is tuple of the form (r,g,b) specifying the background color of the text","metadata":{}},{"cell_type":"code","source":"# for kaggle uae (0,0,0) and (255,255,255)\ndef print_in_color(txt_msg,fore_tupple= (64, 64, 64) ,back_tupple=(230, 230, 230)):\n    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n    rf,gf,bf=fore_tupple\n    rb,gb,bb=back_tupple\n    msg='{0}' + txt_msg\n    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n    print(msg .format(mat))\n    print('\\33[0m', end='') # returns default print color to back to black","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:41.853919Z","iopub.execute_input":"2023-12-17T23:32:41.854246Z","iopub.status.idle":"2023-12-17T23:32:41.870499Z","shell.execute_reply.started":"2023-12-17T23:32:41.854216Z","shell.execute_reply":"2023-12-17T23:32:41.869761Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"pcounts\"></a>\n## <center>Define a function that plots value counts for a column in a dataframe</center>","metadata":{}},{"cell_type":"code","source":"def plot_label_count (df, plot_title):\n    column='labels'\n    xaxis_label='CLASS'\n    yaxis_label='IMAGE COUNT'\n    vcounts=df[column].value_counts()\n    labels=vcounts.keys().tolist()    \n    values=vcounts.tolist() \n    lcount=len(labels)\n    if lcount>55:\n        print_in_color('The number of labels is >55, no plot will be produced')\n    else:\n        width=lcount * 4\n        width=np.min([width, 10])\n        plt.figure(figsize=(width,5)) \n        form = {'family': 'serif', 'color': 'green', 'size': 15} \n        plt.bar(labels, values)\n        plt.title(plot_title, fontsize= 20, color='green')\n        plt.xticks(rotation=90, fontsize=10)\n        plt.yticks(fontsize=10)\n        plt.xlabel(xaxis_label, fontdict=form)\n        plt.ylabel(yaxis_label, fontdict=form)\n        if lcount >=8:\n            rotation='vertical'\n        else:\n            rotation='horizontal'\n        for i in range(lcount):\n            plt.text(i, values[i]/2, str(values[i]),fontsize=12, rotation=rotation, color='black', ha='center')        \n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:41.872198Z","iopub.execute_input":"2023-12-17T23:32:41.872481Z","iopub.status.idle":"2023-12-17T23:32:41.883835Z","shell.execute_reply.started":"2023-12-17T23:32:41.872457Z","shell.execute_reply":"2023-12-17T23:32:41.883129Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"check\"></a>\n# <center>Define a function to return information of the training data</center>\n* train_dir is a string specifying the full path to the directory holding the training images\nThe function determines the total number of training images, the class with the most image files      \nand their number and the class with the least image files and their number. This information is      \nprovided to the used to enable selection of various program parameters","metadata":{}},{"cell_type":"code","source":"def check_dataset_size(train_dir):\n    classes=sorted(os.listdir(train_dir))\n    ftotal=0\n    flargest=0\n    fsmallest=100000000\n    for klass in classes:\n        classpath=os.path.join(train_dir,klass)\n        if os.path.isdir(classpath):\n            flist=os.listdir(classpath)\n            fcount=len(flist)\n            if fcount>flargest:\n                flargest=fcount\n                maxclass=klass\n            if fcount < fsmallest:\n                fsmallest=fcount\n                minclass=klass\n            ftotal += fcount\n    return ftotal, flargest, maxclass, fsmallest, minclass","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:41.885008Z","iopub.execute_input":"2023-12-17T23:32:41.885325Z","iopub.status.idle":"2023-12-17T23:32:41.902024Z","shell.execute_reply.started":"2023-12-17T23:32:41.885301Z","shell.execute_reply":"2023-12-17T23:32:41.901352Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"makedf\"></a>\n# <center>Read in data and create train, test and validation data frames</center>\n","metadata":{}},{"cell_type":"code","source":"def make_dataframes(train_dir,test_dir, val_dir, limiter):\n    bad_images=[]\n    # check what directories exist\n    if test_dir == None and val_dir==None:\n        dirlist=[train_dir]\n        names = ['train']\n    elif test_dir == None:\n        dirlist=[train_dir,  val_dir]\n        names=['train', 'valid']\n    elif val_dir == None:\n        dirlist=[train_dir,  test_dir]\n        names=['train', 'test'] \n    else:\n        dirlist=[train_dir, test_dir, val_dir]\n        names=['train','test', 'valid']\n    ht=0 # set initial value of height counter\n    wt=0  # set initial value of width counter\n    total_good_files=0 # set initial value of total number of good image files counter\n    zipdir=zip(names, dirlist)\n    for name,d in zipdir: #iterate through the  names and directories\n        filepaths=[] # initialize list of filepaths\n        labels=[] # initialize list of class labels\n        classlist=sorted(os.listdir(d) )   # get a list of all the classes in alphanumeric order   \n        for klass in classlist: # iterate through the list of classes\n            msg=f'processing images in {name} directory for class {klass}                                                  '\n            print(msg, '\\r', end='')\n            good_file_count=0 # initialize the good_file count for this class\n            classpath=os.path.join(d, klass) # define the full path to the class            \n            if os.path.isdir(classpath): # ensure we are working with a directory and not a spurious file\n                flist=sorted(os.listdir(classpath)) # make a list of all the files for this class\n                if limiter != None: # check if a limiter value was specified that determmine how many files to use in any class\n                    if limiter <len(flist): # if there are more files than the value of limiter than randomly sample a limiter number of files\n                        flist=np.random.choice(flist, limiter, replace=False)                        \n                for f in flist:\n                    fpath=os.path.join(classpath,f) # create the full path to the image file\n                    index=f.rfind('.')\n                    ext=f[index+1:].lower() # the the file's extension\n                    if ext not in ['jpg', 'jpeg', 'tiff', 'png', 'bmp'] :   # make sure the file extension is one that works with Keras                     \n                        bad_images.append(fpath) # if not a proper extension store the filepath in the bad images list\n                    else:                    \n                        try: # check if image files are defective if so do not include in dataframe\n                            img=cv2.imread(fpath)\n                            h=img.shape[0]\n                            w=img.shape[1]\n                            ht +=h # add images height and width to the counters\n                            wt += w                    \n                            good_file_count +=1   \n                            total_good_files +=1\n                            filepaths.append(fpath) # append the filepath to the list of valid filepaths\n                            labels.append(klass) # append the file's class label to the labels list\n\n                        except:\n                            bad_images.append(fpath) # if the image file is defective add the filepath to the list of bad images\n        print('')\n        Fseries=pd.Series(filepaths, name='filepaths') # make a pandas series for the filenames and labels lists\n        Lseries=pd.Series(labels, name='labels')\n        df=pd.concat([Fseries, Lseries], axis=1) # make a dataframe with columns filepaths and labels\n        # depending on which directory we are iterating through create dataframes\n        if name =='valid':\n            valid_df=df\n        elif name == 'test':\n            test_df=df\n        else:\n            if test_dir == None and val_dir == None: # create train_df, test_df and valid_df from df\n                pdf=df\n                train_df, dummy_df=train_test_split(pdf, train_size=.8, shuffle=True, random_state=123, stratify=pdf['labels'])\n                valid_df, test_df=train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123, stratify=dummy_df['labels'])\n            elif test_dir == None: # create just a train_df and test_df \n                pdf=df\n                train_df,test_df=train_test_split(pdf, train_size=.8, shuffle=True, random_state=123, stratify=pdf['labels'])\n            elif val_dir == None:  # create a train_df and a valid_df                          \n                pdf=df                \n                train_df,valid_df=train_test_split(pdf, train_size=.8, shuffle=True, random_state=123, stratify=pdf['labels'])\n            else:\n                train_df= df # test and valid dataframes exists so train_df is just df\n    classes=sorted(train_df['labels'].unique())\n    class_count=len(classes)    \n    # calculate the average image height and with \n    have=int(ht/total_good_files)\n    wave=int(wt/total_good_files)\n    aspect_ratio=have/wave\n    print('number of classes in processed dataset= ', class_count)    \n    counts=list(train_df['labels'].value_counts())    \n    print('the maximum files in any class in train_df is ', max(counts), '  the minimum files in any class in train_df is ', min(counts))\n    print('train_df length: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df)) \n    if len(bad_images) == 0:\n        print_in_color('All image files were properly processed and used in the dataframes')\n    else:\n        print_in_color(f'the are {len(bad_images)} bad image files and {total_good_files} proper image files in the dataset')\n        for f in bad_images:\n            print (f)                       \n    plot_title='Images per Label in train set'\n    plot_label_count (train_df,  plot_title)\n    return train_df, test_df, valid_df, classes, class_count, max(counts), min(counts), have, wave","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:41.978942Z","iopub.execute_input":"2023-12-17T23:32:41.979224Z","iopub.status.idle":"2023-12-17T23:32:42.001728Z","shell.execute_reply.started":"2023-12-17T23:32:41.979202Z","shell.execute_reply":"2023-12-17T23:32:42.000823Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"trim\"></a>\n## <center>Define a function that trims the classes in a dataframe</center>\n* df is the dataframe\n* max_samples is an integer specifies the maximum number of images a class can have\n* min_samples is an integer specifying the minimum number of images a class must have to be included in the trimmed dataframe\n* column is a string specifying the column name in the dataframe holding the class labels ","metadata":{}},{"cell_type":"code","source":"def trim(df, max_samples, min_samples, column):\n    # column specifies which column of the dataframe to use, typically this is the labels column\n    # df is typically train_df\n    df=df.copy()\n    classes=df[column].unique() # get the classes in df\n    class_count=len(classes)\n    length=len(df)\n    print ('dataframe initially is of length ',length, ' with ', class_count, ' classes')\n    groups=df.groupby(column)   # creates a set of  dataframes that only contains rows that have the class label  \n    trimmed_df = pd.DataFrame(columns = df.columns) # create an empty dataframe with columns filepaths, labels    \n    for label in df[column].unique(): # iterate through each class label\n        group=groups.get_group(label) # get the dataframe associate with the label\n        count=len(group) # determine how many files are in the dataframe   \n        if count > max_samples: # if there more files in the dataframe sample it so the sampled files has only n rows\n            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0) # add the sampled files to the trimmed_df dataframe\n        else:\n            if count>=min_samples: # if the dataframe has more than the minimum number of files include it in the dataset\n                sampled_group=group        \n                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n    classes=trimmed_df[column].unique()# return this in case some classes have less than min_samples\n    class_count=len(classes) # return this in case some classes have less than min_samples and so will have less classes in it\n    length=len(trimmed_df)\n    print ('the trimmed dataframe now is of length ',length, ' with ', class_count, ' classes')\n    return trimmed_df, classes, class_count\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.003805Z","iopub.execute_input":"2023-12-17T23:32:42.004146Z","iopub.status.idle":"2023-12-17T23:32:42.018648Z","shell.execute_reply.started":"2023-12-17T23:32:42.004114Z","shell.execute_reply":"2023-12-17T23:32:42.018018Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"balance\"></a>\n## <center>Expand train_df rows with augmented images so each class has n samples</center>\n* df is the dataframe\n* n is an integer specifying the number of images desired for each class\n* column is a string specifying the column name of the dataframe that contains the class labels\n* working_dir is a string specifying the path where augmented images will be stored\n* img_size is a tupple (height,width) specifying the image size of the augmented images created","metadata":{}},{"cell_type":"code","source":"def balance(df, n,column, working_dir, img_size):    \n    def get_augmented_image(image): # given an image this function returns an augmented image\n        width=int(image.shape[1]*.8)\n        height=int(image.shape[0]*.8)\n        transform= A.Compose([\n            A.HorizontalFlip(p=.5),\n            A.Rotate(limit=30, p=.25),\n            A.RandomBrightnessContrast(p=.5),\n            A.RandomGamma(p=.5),\n            A.RandomCrop(width=width, height=height, p=.25) ])    \n        return transform(image=image)['image']\n    def dummy(image):\n        return image\n\n    df=df.copy()\n    print('Initial length of dataframe is ', len(df))\n    aug_dir=os.path.join(working_dir, 'aug')# directory to store augmented images\n    if os.path.isdir(aug_dir):# start with an empty directory\n        shutil.rmtree(aug_dir)\n    os.mkdir(aug_dir)        \n    for label in df[column].unique():    \n        dir_path=os.path.join(aug_dir,label)    \n        os.mkdir(dir_path) # make class directories within aug directory\n    # create and store the augmented images  \n    total=0    \n    groups=df.groupby(column) # group by class\n    for label in df[column].unique():  # for every class\n        msg=f'augmenting images in train set  for class {label}                                              '\n        print(msg, '\\r', end='')        \n        group=groups.get_group(label)  # a dataframe holding only rows with the specified label \n        sample_count=len(group)   # determine how many samples there are in this class  \n        if sample_count< n: # if the class has less than target number of images\n            aug_img_count=0\n            delta=n - sample_count  # number of augmented images to create\n            target_dir=os.path.join(aug_dir, label)  # define where to write the images            \n            desc=f'augmenting class {label:25s}'\n            for i in range(delta):                \n                j= i % sample_count # need this because we may have to go through the image list several times to get the needed number\n                img_path=group['filepaths'].iloc[j]\n                img=cv2.imread(img_path)\n                img=get_augmented_image(img)\n                fname=os.path.basename(img_path)\n                fname='aug' +str(i) +'-' +fname\n                dest_path=os.path.join(target_dir, fname)                \n                cv2.imwrite(dest_path, img)\n                aug_img_count +=1\n            total +=aug_img_count\n    print('')\n    print('Total Augmented images created= ', total)\n    # create aug_df and merge with train_df to create composite training set ndf\n    aug_fpaths=[]\n    aug_labels=[]\n    classlist=sorted(os.listdir(aug_dir))\n    for klass in classlist:\n        classpath=os.path.join(aug_dir, klass)     \n        flist=sorted(os.listdir(classpath))    \n        for f in flist:        \n            fpath=os.path.join(classpath,f)         \n            aug_fpaths.append(fpath)\n            aug_labels.append(klass)\n    Fseries=pd.Series(aug_fpaths, name='filepaths')\n    Lseries=pd.Series(aug_labels, name='labels')   \n    aug_df=pd.concat([Fseries, Lseries], axis=1)         \n    df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\n    print('Length of augmented dataframe is now ', len(df))    \n    return df ","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.019798Z","iopub.execute_input":"2023-12-17T23:32:42.020129Z","iopub.status.idle":"2023-12-17T23:32:42.038349Z","shell.execute_reply.started":"2023-12-17T23:32:42.020097Z","shell.execute_reply":"2023-12-17T23:32:42.037642Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"gens\"></a>\n# <center>Create the train_gen, test_gen  and valid_gen</center>\n* batch_size is an integer specifying the generator batch size\n* ycol is a string specifying the dataframe column containing the class labels\n* train_df is the dataframe containing the training images\n* test_df is the dataframe containing the test images\n* valid_df is the dataframe containing the validation images\n* image_size is a tupple (height, width)","metadata":{}},{"cell_type":"code","source":"def make_gens(batch_size, ycol, train_df, test_df, valid_df, img_size):\n    gen=ImageDataGenerator() \n    msg='{0:70s} for train generator'.format(' ')\n    print(msg, '\\r', end='') # prints over on the same line\n    train_gen=gen.flow_from_dataframe(train_df, x_col='filepaths', y_col=ycol, target_size=img_size,\n                                       class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n    msg='{0:70s} for valid generator'.format(' ')\n    print(msg, '\\r', end='') # prints over on the same line\n    valid_gen=gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col=ycol, target_size=img_size,\n                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n    # for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n    # this insures that we go through all the sample in the test set exactly once.\n    length=len(test_df)\n    test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n    test_steps=int(length/test_batch_size)    \n    msg='{0:70s} for test generator'.format(' ')\n    print(msg, '\\r', end='') # prints over on the same line\n    test_gen=gen.flow_from_dataframe(test_df, x_col='filepaths', y_col=ycol, target_size=img_size,\n                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n    # from the generator we can get information we will need later\n    classes=list(train_gen.class_indices.keys())\n    class_indices=list(train_gen.class_indices.values())\n    class_count=len(classes)\n    labels=test_gen.labels    \n    return train_gen, test_gen, valid_gen, test_steps, class_count","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-17T23:32:42.039466Z","iopub.execute_input":"2023-12-17T23:32:42.039801Z","iopub.status.idle":"2023-12-17T23:32:42.055946Z","shell.execute_reply.started":"2023-12-17T23:32:42.039770Z","shell.execute_reply":"2023-12-17T23:32:42.055252Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"show\"></a>\n# <center>Create a function to show example training images</center>\n* gen is the ImageDataGenerator containing the images to be displayed","metadata":{}},{"cell_type":"code","source":"def show_image_samples(gen ):\n    msg='Below are some example training images'\n    print_in_color(msg)\n    t_dict=gen.class_indices\n    classes=list(t_dict.keys())    \n    images,labels=next(gen) # get a sample batch from the generator \n    plt.figure(figsize=(20, 20))\n    length=len(labels)\n    if length<15:   #show maximum of 25 images\n        r=length\n    else:\n        r=25\n    for i in range(r):        \n        plt.subplot(5, 5, i + 1)\n        image=images[i] /255       \n        plt.imshow(image)\n        index=np.argmax(labels[i])\n        class_name=classes[index]\n        plt.title(class_name, color='green', fontsize=18)\n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.058106Z","iopub.execute_input":"2023-12-17T23:32:42.058374Z","iopub.status.idle":"2023-12-17T23:32:42.073240Z","shell.execute_reply.started":"2023-12-17T23:32:42.058351Z","shell.execute_reply":"2023-12-17T23:32:42.072469Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"f1metric\"></a>\n# <center>Create a function to calculate the F1 score metric</center>\n* y_true is an np array containing the true integer index of  the associated image file\n* y_pred is an np array containing the predicted integer index of a test image in the test dataframe","metadata":{}},{"cell_type":"code","source":"def F1_score(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n    return f1_val","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.074183Z","iopub.execute_input":"2023-12-17T23:32:42.074452Z","iopub.status.idle":"2023-12-17T23:32:42.089051Z","shell.execute_reply.started":"2023-12-17T23:32:42.074426Z","shell.execute_reply":"2023-12-17T23:32:42.088207Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"model\"></a>\n## <center>Create a small, medium or large model using transfer learning </center>\n* img_size is a tupple (height, width)\n* class_count is an integer that specifies the number of classes in the dataset\n* lr is a float specifying the intial model's learning rate\n* ans is a string. If ans is an empty string an EfficientNetB0 model is used for transfer learning,  \n  is ans='S' a MobilenetV3-small model is used for transfer learning. If ans='L' an \n  EfficientNetB3 model is used for transfer learning","metadata":{}},{"cell_type":"code","source":"\ndef make_model(img_size, class_count, lr, ans):\n    img_shape = (img_size[0], img_size[1], 3)\n    if ans == 's' or ans == 'S':\n        base_model = tf.keras.applications.MobileNetV3Small(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n        msg = 'Created MobileNet V3 Small model'\n    elif ans == 'l' or ans == 'L':\n        base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n        msg = 'Created EfficientNet B3 model'\n    elif ans == 'i' or ans == 'I':\n        base_model = tf.keras.applications.InceptionV3(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n        msg = 'Created Inception V3 model'\n    else:\n        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n        msg = 'Created EfficientNet B0 model'\n\n    base_model.trainable = True\n    x = base_model.output\n    x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n    x = Dense(256, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n              bias_regularizer=regularizers.l1(0.006), activation='relu')(x)\n    x = Dropout(rate=0.4, seed=123)(x)\n    output = Dense(class_count, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=output)\n    model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy', F1_score])\n    msg = msg + f' with initial learning rate set to {lr}'\n    print_in_color(msg)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.090189Z","iopub.execute_input":"2023-12-17T23:32:42.090515Z","iopub.status.idle":"2023-12-17T23:32:42.102363Z","shell.execute_reply.started":"2023-12-17T23:32:42.090485Z","shell.execute_reply":"2023-12-17T23:32:42.101644Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"callback\"></a>\n# <center>Create a custom Keras callback to continue or halt training</center>\nThe LR_ASK callback is a convenient callback that allows you to continue training for ask_epoch more epochs or to halt training.  \nIf you elect to continue training for more epochs you are given the option to retain the current learning rate (LR) or to  \nenter a new value for the learning rate. The form of use is:  \nask=LR_ASK(model,epochs, ask_epoch) where:  \n* model is a string which is the name of your compiled model\n* epochs is an integer which is the number of epochs to run specified in model.fit\n* ask_epoch is an integer. If ask_epoch is set to a value say 5 then the model will train for 5 epochs.  \n  then the user is ask to enter H to halt training, or enter an inter value. For example if you enter 4  \n  training will continue for 4 more epochs to epoch 9 then you will be queried again. Once you enter an  \n  integer value you are prompted to press ENTER to continue training using the current learning rate  \n  or to enter a new value for the learning rate.\n * dwell is a boolean. If set to true the function compares the validation loss for the current tp the lowest   \n   validation loss thus far achieved. If the validation loss for the current epoch is larger then learning rate  \n   is automatically adjust by the formulanew_lr=lr * factor where factor is a float between 0 and 1. The motivation  \n   here is that if the validation loss increased we have moved to a point in Nspace on the cost functiob surface that  \n   if less favorable(higher cost) than for the epoch with the lowest cost. So the model is loaded with the weights\n   from the epoch with the lowest loss and the learning rate is reduced\n  \n At the end of training the model weights are set to the weights for the epoch that achieved the lowest validation loss","metadata":{}},{"cell_type":"code","source":"class LR_ASK(keras.callbacks.Callback):\n    def __init__ (self, model, epochs,  ask_epoch, batches, dwell=True, factor=.4): # initialization of the callback\n        super(LR_ASK, self).__init__()\n        self.model=model               \n        self.ask_epoch=ask_epoch\n        self.epochs=epochs\n        self.ask=True # if True query the user on a specified epoch\n        self.lowest_vloss=np.inf\n        self.lowest_aloss=np.inf\n        self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n        self.best_epoch=1        \n        self.dwell= dwell\n        self.factor=factor\n        self.header=True\n        self.batches=batches\n    \n    def on_train_begin(self, logs=None): # this runs on the beginning of training \n        msg1 =f'Training will proceed until epoch {self.ask_epoch} then you will be asked to\\n'\n        msg2='enter H to halt training or enter an integer for how many more epochs to run then be asked again'\n        print_in_color(msg1 + msg2)\n        if self.dwell:\n            msg='learning rate will be automatically adjusted during training'\n            print_in_color(msg, (0,255,0))\n        self.start_time= time.time() # set the time at which training started\n       \n    def on_train_end(self, logs=None):   # runs at the end of training  \n        msg=f'loading model with weights from epoch {self.best_epoch}'\n        print_in_color(msg, (0,255,255))\n        self.model.set_weights(self.best_weights) # set the weights of the model to the best weights\n        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted         \n        hours = tr_duration // 3600\n        minutes = (tr_duration - (hours * 3600)) // 60\n        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n        print_in_color (msg) # print out training duration time\n   \n    def on_epoch_begin(self, epoch, logs= None):\n        self.ep_start = time.time()\n    def on_train_batch_end(self, batch, logs= None):\n        # get batch accuracy and loss\n        acc = logs.get('accuracy') * 100\n        loss = logs.get('loss')\n        # prints over on the same line to show running batch count\n        msg = '{0:20s}processing batch {1:} of {2:5s}-   accuracy=  {3:5.3f}   -   loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n        print(msg, '\\r', end= '')\n        \n    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n        if self.header == True:\n            msg = '{0:^7s}{1:^9s}{2:^9s}{3:^9s}{4:^10s}{5:^13s}{6:^10s}{7:^13s}{8:13s}\\n'\n            msg1=msg.format('Epoch', 'Train', 'Train', 'Valid', 'Valid','V_Loss %', 'Learning','Next LR' ,'Duration in')\n            msg='{0:^7s}{1:^9s}{2:^9s}{3:^9s}{4:^10s}{5:^13s}{6:^10s}{7:^13s}{8:13s}'\n            msg2=msg.format(' ', 'Loss', 'Accuracy', 'Loss', 'Accuracy','Improvement', 'Rate', 'Rate', '  Seconds') \n            print_in_color (msg1 + msg2)\n            self.header=False\n        ep_end = time.time()\n        duration = ep_end - self.ep_start        \n        vloss=logs.get('val_loss')  # get the validation loss for this epoch\n        aloss=logs.get('loss')\n        acc = logs.get('accuracy')  # get training accuracy\n        v_acc = logs.get('val_accuracy')  # get validation accuracy\n        lr = float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n        if epoch >0:\n            deltav = self.lowest_vloss- vloss \n            pimprov=(deltav/self.lowest_vloss) * 100\n            deltaa=self.lowest_aloss-aloss\n            aimprov=(deltaa/self.lowest_aloss) * 100            \n        else:\n            pimprov=0.0             \n        if vloss< self.lowest_vloss:\n            self.lowest_vloss=vloss\n            self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n            self.best_epoch=epoch + 1 \n            new_lr=lr\n            msg = '{0:^7s}{1:^9.4f}{2:^9.2f}{3:^9.4f}{4:^10.2f}{5:^13.2f}{6:^10.6f}{7:11.6f}{8:^15.2f}'\n            msg=msg.format(str(epoch+1), aloss, acc*100, vloss, v_acc*100, pimprov, lr, new_lr,duration)         \n            print_in_color(msg, (0,255,0)) # green foreground\n        else: # validation loss increased                     \n            if self.dwell: # if dwell is True when the validation loss increases the learning rate is automatically reduced and model weights are set to best weights\n                lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n                new_lr=lr * self.factor\n                msg = '{0:^7s}{1:^9.4f}{2:^9.2f}{3:^9.4f}{4:^10.2f}{5:^13.2f}{6:^10.6f}{7:11.6f}{8:^15.2f}'                 \n                msg=msg.format(str(epoch+1), aloss, acc*100, vloss, v_acc*100, pimprov, lr, new_lr,duration) \n                print_in_color(msg, (255,255,0))                \n                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n                self.model.set_weights(self.best_weights) # set the weights of the model to the best weights                 \n        if self.ask: # are the conditions right to query the user?\n            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?                \n                msg='\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again'\n                print_in_color(msg) # cyan foreground\n                ans=input()\n                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n                    msg=f'you entered {ans},  Training halted on epoch {epoch+1} due to user input\\n'\n                    print_in_color(msg)\n                    self.model.stop_training = True # halt training\n                else: # user wants to continue training\n                    self.header=True\n                    self.ask_epoch += int(ans)\n                    msg=f'you entered {ans} Training will continue to epoch {self.ask_epoch}'\n                    print_in_color(msg) # cyan foreground\n                    if self.dwell==False:\n                        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n                        msg=f'current LR is  {lr:8.6f}  hit enter to keep  this LR or enter a new LR'\n                        print_in_color(msg) # cyan foreground\n                        ans=input(' ')\n                        if ans =='':\n                            msg=f'keeping current LR of {lr:7.5f}'\n                            print_in_color(msg) # cyan foreground\n                        else:\n                            new_lr=float(ans)\n                            tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n                            msg=f' changing LR to {ans}'\n                            print_in_color(msg) # cyan foreground","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.103624Z","iopub.execute_input":"2023-12-17T23:32:42.103879Z","iopub.status.idle":"2023-12-17T23:32:42.130870Z","shell.execute_reply.started":"2023-12-17T23:32:42.103857Z","shell.execute_reply":"2023-12-17T23:32:42.129857Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"plot\"></a>\n# <center>Define a function to plot the training data</center>\n* tr_data is the history data from model.fit","metadata":{}},{"cell_type":"code","source":"def tr_plot(tr_data):\n    start_epoch=0\n    #Plot the training and validation data\n    tacc=tr_data.history['accuracy']\n    tloss=tr_data.history['loss']\n    vacc=tr_data.history['val_accuracy']\n    vloss=tr_data.history['val_loss']\n    tf1=tr_data.history['F1_score']\n    vf1=tr_data.history['val_F1_score']    \n    Epoch_count=len(tacc)+ start_epoch\n    Epochs=[]\n    for i in range (start_epoch ,Epoch_count):\n        Epochs.append(i+1)   \n    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    acc_highest=vacc[index_acc]\n    indexf1=np.argmax(vf1)\n    vf1_highest=vf1[indexf1]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch) \n    f1_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n    fig,axes=plt.subplots(nrows=1, ncols=3, figsize=(15,8))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'green', label=sc_label)\n    axes[0].scatter(Epochs, tloss, s=100, c='orange')    \n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs', fontsize=10)\n    axes[0].set_ylabel('Loss', fontsize=10)\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].scatter(Epochs, tacc, s=100, c='orange')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'green', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs', fontsize=10)\n    axes[1].set_ylabel('Accuracy', fontsize=10)\n    axes[1].legend()\n    axes[2].plot (Epochs,tf1,'r',label= 'Training F1 score')    \n    axes[2].plot (Epochs,vf1,'g',label= 'Validation F1 score')\n    index_tf1=np.argmax(tf1)#  this is the epoch with the highest training F1 score\n    tf1max=tf1[index_tf1]\n    index_vf1=np.argmax(vf1)# thisiis the epoch with the highest validation F1 score\n    vf1max=vf1[index_vf1]\n    axes[2].scatter(index_vf1+1 +start_epoch,vf1max, s=150, c= 'green', label=vc_label)    \n    axes[2].scatter(Epochs, tf1, s=100, c='orange')\n    axes[2].set_title('Training and Validation F1 score')\n    axes[2].set_xlabel('Epochs', fontsize=10)\n    axes[2].set_ylabel('F1  score', fontsize=10)\n    axes[2].legend()    \n    plt.tight_layout    \n    plt.show()\n    return ","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.140922Z","iopub.execute_input":"2023-12-17T23:32:42.141244Z","iopub.status.idle":"2023-12-17T23:32:42.157288Z","shell.execute_reply.started":"2023-12-17T23:32:42.141208Z","shell.execute_reply":"2023-12-17T23:32:42.156446Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"csv\"></a>\n# <center>Define a function to save the training data to a csv file</center>\n* history is the history from history=model.fit\n* csvpath is a string specifying the full path where the csv file will be stored","metadata":{}},{"cell_type":"code","source":"def save_history_to_csv(history,csvpath):\n    trdict=history.history \n    df=pd.DataFrame() \n    df['Epoch']=list(np.arange(1, len(trdict['loss']) + 1 ))\n    keys=list(trdict.keys())     \n    for key in keys:\n        data=list(trdict[key])        \n        df[key]=data   \n    df.to_csv(csvpath, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.159197Z","iopub.execute_input":"2023-12-17T23:32:42.159471Z","iopub.status.idle":"2023-12-17T23:32:42.173113Z","shell.execute_reply.started":"2023-12-17T23:32:42.159447Z","shell.execute_reply":"2023-12-17T23:32:42.172286Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"predict\"></a>\n## <center>Make Predictions on the test set</center>\n### Define a function which takes in a trained model and a test generator  and generates predictions  \n### on the test set including a confusion matrix and a classification report\n* model is the trained model\n* test_gen is the ImageDataGenerator holding the test filepaths and labels\nThe function will produce a classification report, a confusion matrix and a plot of misclassifications","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nimport matplotlib.pyplot as plt\n\n\ndef predictor(model,test_gen):\n    classes=list(test_gen.class_indices.keys())\n    class_count=len(classes)\n    preds=model.predict(test_gen, verbose=1)\n    errors=0\n    test_count =len(preds)\n    misclassified_classes=[]\n    misclassified_files=[]\n    misclassified_as = []\n    pred_indices=[]\n    for i, p in enumerate (preds):\n        pred_index=np.argmax(p)\n        pred_indices.append(pred_index)\n        true_index= test_gen.labels[i]    \n        if  pred_index != true_index:        \n            errors +=1        \n            misclassified_classes.append(classes[true_index])\n            misclassified_as.append(classes[pred_index])\n            file=test_gen.filenames[i]\n            split=file.split('/')\n            L=len(split)           \n            f=split[L-2] +' '+ split[L-1]  \n            misclassified_files.append(f)\n\n    accuracy = (test_count-errors)*100/test_count\n    ytrue=np.array(test_gen.labels)\n    ypred=np.array(pred_indices)\n    f1score=f1_score(ytrue, ypred, average='weighted')* 100\n    msg=f'There were {errors} errors in {test_count} tests for an accuracy of {accuracy:6.2f} and an F1 score of {f1score:6.2f}'\n    print (msg) \n    misclassified_classes=sorted(misclassified_classes)\n    if len(misclassified_classes) > 0:\n        misclassifications=[]\n        for klass in misclassified_classes:\n            mis_count=misclassified_classes.count(klass)\n            misclassifications.append(mis_count)\n        unique=len(np.unique(misclassified_classes)) \n        if unique==1:\n            height=int(unique)\n        else:\n            height =int(unique/2)\n        plt.figure(figsize=(8, height))\n        plt.style.use('fivethirtyeight')\n        plt.barh(misclassified_classes, misclassifications )\n        plt.title( 'Classification Errors on Test Set by Class', fontsize=8, color='green')\n        plt.xlabel('NUMBER OF MISCLASSIFICATIONS', fontsize=8, color='green')\n        plt.ylabel('CLASS', fontsize=8, color='green')\n        plt.show()\n    if class_count <=30:\n        cm = confusion_matrix(ytrue, ypred )\n        # plot the confusion matrix\n        plt.figure(figsize=(8, 6))\n        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Greens', cbar=False)       \n        plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n        plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.title(\"Confusion Matrix\")\n        plt.show()\n        clr = classification_report(ytrue, ypred, target_names=classes, digits= 4) # create classification report\n        print(\"Classification Report:\\n----------------------\\n\", clr)\n        y_true = label_binarize(test_gen.labels, classes=range(class_count))\n        y_pred = model.predict(test_gen, verbose=1)\n\n        # Calculate ROC for each class\n        fpr = dict()\n        tpr = dict()\n        roc_auc = dict()\n        for i in range(class_count):\n            fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n            roc_auc[i] = auc(fpr[i], tpr[i])\n\n        # Plot all ROC curves\n        plt.figure()\n        for i in range(class_count):\n            plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n\n        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver Operating Characteristic for each class')\n        plt.legend(loc=\"lower right\")\n        plt.show()\n\n\n    return f1score\n        \n  ","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.174514Z","iopub.execute_input":"2023-12-17T23:32:42.174850Z","iopub.status.idle":"2023-12-17T23:32:42.195309Z","shell.execute_reply.started":"2023-12-17T23:32:42.174819Z","shell.execute_reply":"2023-12-17T23:32:42.194485Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"save\"></a>\n# <center>Save the model </center>","metadata":{}},{"cell_type":"code","source":"def save_model(model,subject, classes, img_size, f1score, working_dir):    \n    name=f'{subject}-{str(len(classes))}-({str(img_size[0])} X {str(img_size[1])})- {f1score:5.2f}.h5'    \n    model_save_loc=os.path.join(working_dir, name)\n    try:\n        model.save(model_save_loc)        \n        msg= f'model was saved as {model_save_loc}'\n        print_in_color(msg, (0,255,255),(0,0,0))\n    except:\n        msg='model can not be saved due to tensorflow 2.10.0 or higher. Bug involving use of EfficientNet Models'        \n        print_in_color(msg, (0,255,255), (0,0,0)) # cyan foreground","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.196368Z","iopub.execute_input":"2023-12-17T23:32:42.196651Z","iopub.status.idle":"2023-12-17T23:32:42.212680Z","shell.execute_reply.started":"2023-12-17T23:32:42.196627Z","shell.execute_reply":"2023-12-17T23:32:42.211866Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"run\"></a>\n# <center>Define a function that runs the classifier</center>\nThis is the code that provides the interface to the user and calls the various defined functions based on the users input. To follow how the program works start here. You can run this function as many times as you care to if you want to do runs with various different parameters. You can save the data from each run in a csv file to compare training and validation results from different runs. ","metadata":{}},{"cell_type":"code","source":"def run(working_dir= None,train_dir=None, test_dir=None, valid_dir=None,start=True):\n    if start:\n        msg='enter the full path to the working directory where data will be stored.'\n        print_in_color(msg)\n        working_dir=input(' ')\n        if 'kaggle' in working_dir: # if running the notebook on kaggle need to modify so parameters\n            delimiter='/'\n        else:\n            delimiter='\\\\'\n        msg='Enter the full path to the train directory'\n        print_in_color(msg)\n        train_dir =input(' ')\n        msg = 'Enter the full path to the validation directory. If there is no validation directory press enter'\n        print_in_color(msg)\n        ans=input(' ')\n        if ans == '':\n            valid_dir=None\n        else:\n            valid_dir=ans\n        msg = 'Enter the full path to the test directory. If there is no test directory press enter'\n        print_in_color(msg)\n        ans=input(' ')\n        if ans == '':\n            test_dir=None\n        else:\n            test_dir=ans\n                                                      \n    ftotal, flargest, maxclass , fsmallest, minclass= check_dataset_size(train_dir) # get info on training data\n    msg1= f'the train directory contains {ftotal} files, class {maxclass} has the most images of {flargest} files\\n'\n    msg2= f'class {minclass} contains the least number of images of {fsmallest} files\\n'\n    msg3= f'NOTE if the value of most images is the same as the value of least images the dataset is balanced\\n'\n    msg4='When dealing with very large data sets to save time you may not want to read in all the image files\\n'\n    msg5 ='to limit the maximum number of image files in any class you can enter an integer limiter value'\n    msg=msg1 +msg2 + msg3 + msg4 + msg5\n    print_in_color(msg) # print the training data information for the user\n    msg = 'input a limiter integer value to limit max number of images in a class, for no limit hit enter'\n    print_in_color(msg)\n    limiter=input(' ')\n    if limiter == '':\n        limiter = None\n        msg='dataset will be processed as is with no limiter'\n        print_in_color(msg)\n    else:\n        limiter=int(limiter)\n        msg=f'images will be limited to a maximum of {limiter} images in each class'\n        print_in_color(msg) \n    # create train, test and valid data frames\n    train_df, test_df, valid_df, classes, class_count, max_samples, min_samples, have, wave=make_dataframes(train_dir,test_dir, valid_dir, limiter)\n    msg=f'the average height of training images is {have} and average width is {wave}\\n  enter the image height to be used to train the model'            \n    print_in_color(msg)\n    img_height=int(input(' '))\n    msg=' Enter the image width to be used to train the model' \n    print_in_color(msg)\n    img_width=int(input(' '))\n    img_size=(img_height, img_width)\n    msg=f'model will be trained with image shape of  ( {img_height}, {img_width} )'    \n    print_in_color(msg)\n    # determine if user wants to balance the training dataframe\n    msg=' enter A  to auto balance the train set or enter or hit enter to leave train set unchanged  '\n    print_in_color(msg)\n    ans=input(' ')\n    if ans == 'A' or ans =='a':\n        msg='enter the number of images you want to have in each class of the train data set'\n        print_in_color(msg)\n        max_images=int(input(' '))  \n        train_df, classes, class_count=trim (train_df, max_images, min_samples, 'labels') # trim the dataset for max images in a class\n        train_df=balance(train_df, max_images, 'labels', working_dir, img_size) # balance the training data with augmented images   \n        plot_title='Images per Label after Auto Balance of train data set'\n        plot_label_count (train_df,  plot_title)  # plot the number of images in each class of the training set        \n    else:        \n        msg=f'training data set will be used as is '\n        print_in_color (msg)  \n    classes=list(train_df['labels'].unique())\n    class_count = len(classes)\n    # make train, test and valid data generators\n    msg='enter the desired batch size or press enter to use the default batch size of 20  '\n    print_in_color(msg)\n    ans=input(' ')\n    if ans =='':\n        bs=20\n    else:\n        bs=int(ans)\n    # make the train, test and valid data generators\n    train_gen, test_gen, valid_gen, test_steps, class_count= make_gens(bs, 'labels', train_df, test_df, valid_df, img_size)\n    show_image_samples(train_gen ) # show some sample training images\n    msg='select model size enter S for small, L for large or hit enter (recommended) for medium size model'\n    print_in_color(msg)\n    print('',end='')\n    ans=input(' ')\n    # make the model\n    model = make_model(img_size,class_count, .001, ans) # create the model\n    epochs=100\n    ask_epoch=10\n    batches=int(len(train_df)/bs)\n    # instantiate the custom callback\n    ask=LR_ASK(model, epochs=epochs,  ask_epoch=ask_epoch, batches=batches) # instantiate the custom callback\n    callbacks=[ask]    \n    # train the model\n    history=model.fit(x=train_gen,   epochs=epochs, verbose=0, callbacks=callbacks,  validation_data=valid_gen,\n                   validation_steps=None,  shuffle=True,  initial_epoch=0) # train the model\n    \n    tr_plot(history) # plot training data\n    msg='To save the training data to a csv file enter the name for the csv file or press enter to not save the data'\n    print_in_color(msg)\n    ans=input(' ')\n    if ans !='': # save the training data to a csv file history.csv in working directory\n        csvpath=os.path.join(working_dir, ans + '.csv')\n        save_history_to_csv(history,csvpath)\n        msg=f'training data saved to {csvpath}'\n        print_in_color(msg)\n    # make predictions on the test set, create classification report and confusion matrix\n    f1score=predictor(model,test_gen) # do predictions on test set and generate reports \n    # save the model\n    msg=f'your trained model will be saved to directory {working_dir} enter a subject for the saved model'\n    print_in_color(msg)\n    subject=input(' ')\n    save_model(model,subject, classes, img_size, f1score, working_dir) # save the model to the working directory\n    msg='model save nomenclature is directory/subject-number of classes- (img_height, img_width)- F1score.h5'\n    print_in_color(msg) \n    # remove the aug directory from the working directory\n    if os.path.isdir(os.path.join(working_dir, 'aug')):\n        shutil.rmtree(os.path.join(working_dir, 'aug')) #remove the augmentation directory it is no longer needed\n    return working_dir,train_dir, test_dir, valid_dir","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.214692Z","iopub.execute_input":"2023-12-17T23:32:42.214926Z","iopub.status.idle":"2023-12-17T23:32:42.237717Z","shell.execute_reply.started":"2023-12-17T23:32:42.214905Z","shell.execute_reply":"2023-12-17T23:32:42.236860Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cycle\"></a>\n# <center>Initiate the run function and enable ability to execute run  multiple times</center>\nThe code below initiate the first run of the classifier and lets the user rerun the classifier","metadata":{}},{"cell_type":"code","source":"working_dir,train_dir, test_dir, valid_dir=run(start=True) # run the classifier\nstop = False\nwhile stop == False:\n    msg='enter R to rerun the classifier or press enter to quit  '\n    print_in_color(msg)\n    ans=input(' ')\n    if ans == 'R' or ans == 'r':\n        msg='press Enter to us original director values '\n        print_in_color(msg)\n        ans=input(' ')\n        if ans == '':\n            run(working_dir,train_dir=train_dir, test_dir=test_dir, valid_dir=valid_dir, start=False ) \n        else:\n            run(True)\n    else:\n        stop = True\n        print_in_color ('process commpleted')","metadata":{"execution":{"iopub.status.busy":"2023-12-17T23:32:42.238595Z","iopub.execute_input":"2023-12-17T23:32:42.238825Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[38;2;64;64;64;48;2;230;230;230menter the full path to the working directory where data will be stored.\n\u001b[0m","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  /kaggle/working/\n"},{"name":"stdout","text":"\u001b[38;2;64;64;64;48;2;230;230;230mEnter the full path to the train directory\n\u001b[0m","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  /kaggle/input/5eye-disease-clahe-y-channel-and-gaussian-blurring/updated_5 classes eye disease preprosed image/train\n"},{"name":"stdout","text":"\u001b[38;2;64;64;64;48;2;230;230;230mEnter the full path to the validation directory. If there is no validation directory press enter\n\u001b[0m","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  /kaggle/input/5eye-disease-clahe-y-channel-and-gaussian-blurring/updated_5 classes eye disease preprosed image/val\n"},{"name":"stdout","text":"\u001b[38;2;64;64;64;48;2;230;230;230mEnter the full path to the test directory. If there is no test directory press enter\n\u001b[0m","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  /kaggle/input/5eye-disease-clahe-y-channel-and-gaussian-blurring/updated_5 classes eye disease preprosed image/test\n"},{"name":"stdout","text":"\u001b[38;2;64;64;64;48;2;230;230;230mthe train directory contains 3453 files, class diabetic_retinopathy has the most images of 878 files\nclass retina_disease contains the least number of images of 80 files\nNOTE if the value of most images is the same as the value of least images the dataset is balanced\nWhen dealing with very large data sets to save time you may not want to read in all the image files\nto limit the maximum number of image files in any class you can enter an integer limiter value\n\u001b[0m\u001b[38;2;64;64;64;48;2;230;230;230minput a limiter integer value to limit max number of images in a class, for no limit hit enter\n\u001b[0m","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  \n"},{"name":"stdout","text":"\u001b[38;2;64;64;64;48;2;230;230;230mdataset will be processed as is with no limiter\nprocessing images in train directory for class retina_disease                                                         \nprocessing images in test directory for class retina_disease                                                         \nprocessing images in valid directory for class retina_disease                                                         \nnumber of classes in processed dataset=  5\nthe maximum files in any class in train_df is  878   the minimum files in any class in train_df is  80\ntrain_df length:  3453   test_df length:  437   valid_df length:  427\n\u001b[38;2;64;64;64;48;2;230;230;230mAll image files were properly processed and used in the dataframes\n\u001b[0m","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\u001b[38;2;64;64;64;48;2;230;230;230mthe average height of training images is 224 and average width is 224\n  enter the image height to be used to train the model\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id=\"Conclusions\"></a>\n# <center>Evaluate Model Performance</center>\nI ran int MobileNetV3 small model with an image size of 200 X 244. After 15 epochs the model achied an F1 score of 73% Next  I ran an EfficientNetB0 model with an image size of 275 X 300. It achieved an F1 score of 94%. ","metadata":{}}]}